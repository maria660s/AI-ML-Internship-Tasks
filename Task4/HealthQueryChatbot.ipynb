{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "3TJXrynXyXyq",
        "outputId": "6c588fd6-9789-4528-f980-dea33b222d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model (this may take a minute)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ©º Health Chatbot â€” powered by Mistral-7B-Instruct\n",
            "Type 'exit' to quit.\n",
            "\n",
            "You: what causes a sore throat?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: A sore throat can be caused by a variety of factors such as viral infections like the common cold or flu, bacterial infections, tonsillitis, strep throat, or even by irritants like smoking or pollution. It's always a good idea to see a healthcare professional if your sore throat persists or is severe.\n",
            "\n",
            "You: How much paracetamol should I give a child?\n",
            "Bot: I'm sorry, I can't give specific medical or dosage advice. Please consult a doctor.\n",
            "You: exit\n",
            "Bot: Stay safe and consult a doctor for any medical concerns.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "\n",
        "# Step 1: Login to Hugging Face\n",
        "HUGGINGFACE_TOKEN = \"HF-Token\"  # ðŸ”’ Replace with your actual token\n",
        "login(token=HUGGINGFACE_TOKEN)\n",
        "\n",
        "# Step 2: Load tokenizer and model\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "print(\"Loading model (this may take a minute)...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=HUGGINGFACE_TOKEN)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    token=HUGGINGFACE_TOKEN,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Step 3: Create generation pipeline\n",
        "chatbot = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Step 4: Prompt engineering\n",
        "def generate_prompt(user_question):\n",
        "    return (\n",
        "        f\"You are a friendly and cautious medical assistant. \"\n",
        "        f\"Provide clear, general health information. \"\n",
        "        f\"Never offer diagnoses or medical treatments. \"\n",
        "        f\"Question: \\\"{user_question}\\\"\\n\"\n",
        "        f\"Answer:\"\n",
        "    )\n",
        "\n",
        "# Step 5: Basic safety filter\n",
        "def is_safe_question(question):\n",
        "    unsafe_keywords = [\n",
        "        \"dosage\", \"how much\", \"prescribe\", \"take\", \"treat\", \"cure\", \"medicine for\",\n",
        "        \"should I take\", \"can I take\", \"pill\", \"tablet\", \"capsule\", \"mg\", \"ml\", \"injection\"\n",
        "    ]\n",
        "    return not any(keyword.lower() in question.lower() for keyword in unsafe_keywords)\n",
        "\n",
        "# Step 6: Chat interface\n",
        "def health_chatbot():\n",
        "    print(\"ðŸ©º Health Chatbot â€” powered by Mistral-7B-Instruct\")\n",
        "    print(\"Type 'exit' to quit.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Bot: Stay safe and consult a doctor for any medical concerns.\")\n",
        "            break\n",
        "\n",
        "        if not is_safe_question(user_input):\n",
        "            print(\"Bot: I'm sorry, I can't give specific medical or dosage advice. Please consult a doctor.\")\n",
        "            continue\n",
        "\n",
        "        prompt = generate_prompt(user_input)\n",
        "        response = chatbot(prompt, max_new_tokens=100, temperature=0.7, do_sample=True)[0][\"generated_text\"]\n",
        "\n",
        "        # Extract and clean the answer\n",
        "        answer = response.split(\"Answer:\")[-1].strip()\n",
        "        print(f\"Bot: {answer}\\n\")\n",
        "\n",
        "# Run the chatbot\n",
        "health_chatbot()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
